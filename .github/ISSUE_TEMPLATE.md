---
title: Latest 15 Papers - June 27, 2025
labels: documentation
---
**Please check the [Github](https://github.com/pstAmbition/DailyArXiv) page for a better reading experience and more papers.**

## Agent
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](http://arxiv.org/abs/2506.21506v1)** | 2025-06-26 | <details><summary>Proje...</summary><p>Project Homepage: https://osu-nlp-group.github.io/Mind2Web2/</p></details> |
| **[From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents](http://arxiv.org/abs/2506.18959v2)** | 2025-06-26 |  |
| **[Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](http://arxiv.org/abs/2506.18019v2)** | 2025-06-26 | 20 pages, 7 figures |
| **[Large Language Model-Powered Agent for C to Rust Code Translation](http://arxiv.org/abs/2505.15858v2)** | 2025-06-26 |  |
| **[xChemAgents: Agentic AI for Explainable Quantum Chemistry](http://arxiv.org/abs/2505.20574v2)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted Paper at ICML 2025 Workshop on MAS</p></details> |
| **[Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](http://arxiv.org/abs/2506.21252v1)** | 2025-06-26 | ACL 2025 Main |
| **[LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey](http://arxiv.org/abs/2505.00753v4)** | 2025-06-26 | <details><summary>Paper...</summary><p>Paper lists and resources are available at https://github.com/HenryPengZou/Awesome-Human-Agent-Collaboration-Interaction-Systems</p></details> |
| **[Performance improvement of spatial semantic segmentation with enriched audio features and agent-based error correction for DCASE 2025 Challenge Task 4](http://arxiv.org/abs/2506.21174v1)** | 2025-06-26 | <details><summary>DCASE...</summary><p>DCASE 2025 challenge Task4, 5 pages</p></details> |
| **[Homogenization of Multi-agent Learning Dynamics in Finite-state Markov Games](http://arxiv.org/abs/2506.21079v1)** | 2025-06-26 |  |
| **[SceneGenAgent: Precise Industrial Scene Generation with Coding Agent](http://arxiv.org/abs/2410.21909v3)** | 2025-06-26 | Accepted to ACL 2025 |
| **[Doppelganger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack](http://arxiv.org/abs/2506.14539v2)** | 2025-06-26 |  |
| **[Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance](http://arxiv.org/abs/2505.19197v3)** | 2025-06-26 | 7 pages, FinIR'25 |
| **[WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis](http://arxiv.org/abs/2412.03359v2)** | 2025-06-26 |  |
| **[Evidence-based diagnostic reasoning with multi-agent copilot for human pathology](http://arxiv.org/abs/2506.20964v1)** | 2025-06-26 |  |
| **[LLM-guided Chemical Process Optimization with a Multi-Agent Approach](http://arxiv.org/abs/2506.20921v1)** | 2025-06-26 | <details><summary>16 pa...</summary><p>16 pages (main manuscript without references), 2 figures</p></details> |

## Misinformation Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs](http://arxiv.org/abs/2506.20944v1)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted to AsiaCCS 2025 @ SCID</p></details> |
| **[A Guide to Misinformation Detection Data and Evaluation](http://arxiv.org/abs/2411.05060v4)** | 2025-06-18 |  |
| **[GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news](http://arxiv.org/abs/2506.11600v1)** | 2025-06-13 | 18 pages, 8 figures |
| **[A Survey of Datasets for Information Diffusion Tasks](http://arxiv.org/abs/2407.05161v2)** | 2025-06-13 |  |
| **[Combating Misinformation in the Arab World: Challenges & Opportunities](http://arxiv.org/abs/2506.05582v1)** | 2025-06-05 | <details><summary>disin...</summary><p>disinformation, misinformation, factuality, harmfulness, fake news</p></details> |
| **[Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning](http://arxiv.org/abs/2505.16836v2)** | 2025-06-04 | 28 pages, 27 figures |
| **[Truth over Tricks: Measuring and Mitigating Shortcut Learning in Misinformation Detection](http://arxiv.org/abs/2506.02350v1)** | 2025-06-03 |  |
| **[Unified Large Language Models for Misinformation Detection in Low-Resource Linguistic Settings](http://arxiv.org/abs/2506.01587v1)** | 2025-06-02 |  |
| **[RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information](http://arxiv.org/abs/2406.11093v2)** | 2025-05-31 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 (Main)</p></details> |
| **[CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection](http://arxiv.org/abs/2505.23449v2)** | 2025-05-30 |  |
| **[Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models](http://arxiv.org/abs/2505.18596v2)** | 2025-05-27 |  |
| **[Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution Generalization of Misinformation Detection Models](http://arxiv.org/abs/2410.18122v2)** | 2025-05-26 | Under review |
| **[Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models](http://arxiv.org/abs/2505.15489v2)** | 2025-05-26 |  |
| **[Community Moderation and the New Epistemology of Fact Checking on Social Media](http://arxiv.org/abs/2505.20067v1)** | 2025-05-26 | 1 Figure, 2 tables |
| **[T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with Monte Carlo Tree Search](http://arxiv.org/abs/2505.19768v1)** | 2025-05-26 |  |

## LLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test](http://arxiv.org/abs/2506.21551v1)** | 2025-06-26 |  |
| **[Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](http://arxiv.org/abs/2506.21497v1)** | 2025-06-26 |  |
| **[Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin Script Languages](http://arxiv.org/abs/2411.02398v3)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted to NAACL 2025 (Main Conference). This version contains minor improvements to the camera-ready</p></details> |
| **[Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](http://arxiv.org/abs/2506.21443v1)** | 2025-06-26 |  |
| **[Rethinking LLM Training through Information Geometry and Quantum Metrics](http://arxiv.org/abs/2506.15830v2)** | 2025-06-26 | 9 pages, 1 figure(s) |
| **[TracLLM: A Generic Framework for Attributing Long Context LLMs](http://arxiv.org/abs/2506.04202v3)** | 2025-06-26 | <details><summary>To ap...</summary><p>To appear in USENIX Security Symposium 2025. The code and data are at: https://github.com/Wang-Yanting/TracLLM</p></details> |
| **[Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](http://arxiv.org/abs/2506.21384v1)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)</p></details> |
| **[Multimodal LLMs for Visualization Reconstruction and Understanding](http://arxiv.org/abs/2506.21319v1)** | 2025-06-26 |  |
| **[Thinkless: LLM Learns When to Think](http://arxiv.org/abs/2505.13379v2)** | 2025-06-26 |  |
| **[Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](http://arxiv.org/abs/2506.21285v1)** | 2025-06-26 | 10 pages |
| **[MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](http://arxiv.org/abs/2506.21199v1)** | 2025-06-26 | <details><summary>40 pa...</summary><p>40 pages, 8 Tables, 9 Figures</p></details> |
| **[LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey](http://arxiv.org/abs/2505.00753v4)** | 2025-06-26 | <details><summary>Paper...</summary><p>Paper lists and resources are available at https://github.com/HenryPengZou/Awesome-Human-Agent-Collaboration-Interaction-Systems</p></details> |
| **[Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](http://arxiv.org/abs/2506.21071v1)** | 2025-06-26 | 20 pages, 12 figures |
| **[Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs](http://arxiv.org/abs/2505.11277v3)** | 2025-06-26 |  |
| **[BLOCKS: Blockchain-supported Cross-Silo Knowledge Sharing for Efficient LLM Services](http://arxiv.org/abs/2506.21033v1)** | 2025-06-26 |  |

## Representation Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning](http://arxiv.org/abs/2506.21541v1)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers](http://arxiv.org/abs/2506.19686v2)** | 2025-06-26 | <details><summary>Updat...</summary><p>Updates: added other funding sources; formatted title correctly</p></details> |
| **[TopK Language Models](http://arxiv.org/abs/2506.21468v1)** | 2025-06-26 |  |
| **[Representation Learning of Lab Values via Masked AutoEncoders](http://arxiv.org/abs/2501.02648v3)** | 2025-06-26 | <details><summary>14 pa...</summary><p>14 pages of main text, 11 appendix</p></details> |
| **[Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols](http://arxiv.org/abs/2506.09803v2)** | 2025-06-26 |  |
| **[These Are Not All the Features You Are Looking For: A Fundamental Bottleneck in Supervised Pretraining](http://arxiv.org/abs/2506.18221v2)** | 2025-06-26 | <details><summary>10 pa...</summary><p>10 pages, 7 figures, Preprint. Under review</p></details> |
| **[Temporal Rate Reduction Clustering for Human Motion Segmentation](http://arxiv.org/abs/2506.21249v1)** | 2025-06-26 | <details><summary>The p...</summary><p>The paper is accepted by ICCV 2025. The first two authors are equally contributed</p></details> |
| **[Capturing Style in Author and Document Representation](http://arxiv.org/abs/2407.13358v2)** | 2025-06-26 |  |
| **[Seal Your Backdoor with Variational Defense](http://arxiv.org/abs/2503.08829v2)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted to ICCV 2025</p></details> |
| **[DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](http://arxiv.org/abs/2506.21096v1)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[Efficient Skill Discovery via Regret-Aware Optimization](http://arxiv.org/abs/2506.21044v1)** | 2025-06-26 |  |
| **[TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence](http://arxiv.org/abs/2506.21028v1)** | 2025-06-26 |  |
| **[Pretrained Reversible Generation as Unsupervised Visual Representation Learning](http://arxiv.org/abs/2412.01787v3)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[Hierarchical Sub-action Tree for Continuous Sign Language Recognition](http://arxiv.org/abs/2506.20947v1)** | 2025-06-26 |  |
| **[Interpretable Representation Learning for Additive Rule Ensembles](http://arxiv.org/abs/2506.20927v1)** | 2025-06-26 |  |

## Multimodal Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](http://arxiv.org/abs/2506.21514v1)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted at ICCV 2025</p></details> |
| **[V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](http://arxiv.org/abs/2506.21041v1)** | 2025-06-26 |  |
| **[TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence](http://arxiv.org/abs/2506.21028v1)** | 2025-06-26 |  |
| **[Where is AIED Headed? Key Topics and Emerging Frontiers (2020-2024)](http://arxiv.org/abs/2506.20971v1)** | 2025-06-26 |  |
| **[LLaVA-CMoE: Towards Continual Mixture of Experts for Large Vision-Language Models](http://arxiv.org/abs/2503.21227v3)** | 2025-06-25 | Preprint |
| **[Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation](http://arxiv.org/abs/2503.05319v2)** | 2025-06-25 | 10pages |
| **[AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning](http://arxiv.org/abs/2506.17364v2)** | 2025-06-24 | <details><summary>Accep...</summary><p>Accepted in EC-TEL25: 20th European Conference on Technology Enhanced Learning, Newcastle and Durham, UK, 15-19 September 2025</p></details> |
| **[Emergence of Text Readability in Vision Language Models](http://arxiv.org/abs/2506.19389v1)** | 2025-06-24 | <details><summary>EVAL-...</summary><p>EVAL-FoMo Workshop @ CVPR 2025</p></details> |
| **[Haptic-ACT -- Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers](http://arxiv.org/abs/2506.18212v1)** | 2025-06-23 | <details><summary>Accep...</summary><p>Accepted at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025) Project website https://upedrou.github.io/haptic-act_IROS2025</p></details> |
| **[Can Generated Images Serve as a Viable Modality for Text-Centric Multimodal Learning?](http://arxiv.org/abs/2506.17623v1)** | 2025-06-21 | 4 figures,7 tables |
| **[With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You](http://arxiv.org/abs/2506.16895v1)** | 2025-06-20 |  |
| **[ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation](http://arxiv.org/abs/2403.01306v4)** | 2025-06-20 | <details><summary>Accep...</summary><p>Accepted to ACL 2024 (Finding). For Project webpage, see https://moranyanuka.github.io/icc/</p></details> |
| **[M3-JEPA: Multimodal Alignment via Multi-gate MoE based on the Joint-Embedding Predictive Architecture](http://arxiv.org/abs/2409.05929v6)** | 2025-06-18 | <details><summary>16 pa...</summary><p>16 pages, 5 figures. ICML 2025</p></details> |
| **[A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion](http://arxiv.org/abs/2506.15747v1)** | 2025-06-18 | 6 pages, 2 figures |
| **[Comparison of ConvNeXt and Vision-Language Models for Breast Density Assessment in Screening Mammography](http://arxiv.org/abs/2506.13964v1)** | 2025-06-16 | 6 pages, 4 figures |

